{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Extra : Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset disponibles :\n",
    "- X_train : avec valeurs Nan , sans transformation (Hyperplot+300 -> 0.677)\n",
    "- X_train_forest_imputed : Nan imputés avec Forest (Hyperplot+300 -> 0.673)\n",
    "- X__Mice_imputed : Nan imputés avec Mice  (Hyperplot+300 -> 0.672)\n",
    "- X_poly_2_No_nan : Nan imputés avec Forest + polynomes et interractions  (Hyperplot+300 -> 0.657)\n",
    "- X_train_RandomUnderSampler , y_train_RandomUnderSampler : données parfaitement équilibrées mais moins importantes. (Hyperplot+300 -> 0.65) \n",
    "- X_train_del : imputation will bring a lot of noise (Hyperplot+300 -> 0.672, 1000 -> 0.673)\n",
    "- X_train_poly2_outnan : polynomes sans OP100 (nan values) (Hyperplot+300 -> 0.657)\n",
    "\n",
    "Les tests nous montrent que quelque soit la méthode d'imputation retenue , il y a perte de performances. Ceci est très probablement du  au fait que la création de bruit par les méthodes d'imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 11:27:22,447] A new study created in memory with name: no-name-263f6c98-9898-4e57-bef1-24e8853c6a28\n",
      "[I 2023-10-29 11:27:22,452] A new study created in memory with name: no-name-a7c178f9-3ae5-4624-8f61-7f0f464b9b8d\n",
      "[I 2023-10-29 11:27:25,712] Trial 0 finished with value: 0.6267820261547529 and parameters: {'n_estimators': 233, 'max_depth': 1, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.21067862744674337}. Best is trial 0 with value: 0.6267820261547529.\n",
      "[I 2023-10-29 11:27:26,531] Trial 1 finished with value: 0.64363574067596 and parameters: {'n_estimators': 17, 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_weight_fraction_leaf': 0.07365139001072918}. Best is trial 1 with value: 0.64363574067596.\n",
      "[I 2023-10-29 11:27:29,052] Trial 2 finished with value: 0.6199371289192596 and parameters: {'n_estimators': 278, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.34068296395225006}. Best is trial 1 with value: 0.64363574067596.\n",
      "[I 2023-10-29 11:27:38,628] Trial 3 finished with value: 0.6568829936601798 and parameters: {'n_estimators': 368, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.0047116888079309915}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:41,244] Trial 4 finished with value: 0.5429147838087799 and parameters: {'n_estimators': 281, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.49882659448688277}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:42,980] Trial 5 finished with value: 0.6418653351287371 and parameters: {'n_estimators': 137, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_weight_fraction_leaf': 0.26380497344003023}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:46,777] Trial 6 finished with value: 0.6395814664487902 and parameters: {'n_estimators': 362, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.26328996915496033}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:49,870] Trial 7 finished with value: 0.6229433920673181 and parameters: {'n_estimators': 373, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6, 'min_weight_fraction_leaf': 0.31520980099787854}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:52,709] Trial 8 finished with value: 0.6363722619692258 and parameters: {'n_estimators': 267, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'min_weight_fraction_leaf': 0.27110492076159554}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:55,399] Trial 9 finished with value: 0.6078205490677158 and parameters: {'n_estimators': 315, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.3955502664336092}. Best is trial 3 with value: 0.6568829936601798.\n",
      "[I 2023-10-29 11:27:57,951] Trial 10 finished with value: 0.6650653389623397 and parameters: {'n_estimators': 136, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.024316863702489405}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:00,802] Trial 11 finished with value: 0.6561728187999866 and parameters: {'n_estimators': 148, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.0017312168622170597}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:03,345] Trial 12 finished with value: 0.6571633258418351 and parameters: {'n_estimators': 154, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1043260970755753}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:05,205] Trial 13 finished with value: 0.6551434965329858 and parameters: {'n_estimators': 120, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.12416002078821563}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:06,640] Trial 14 finished with value: 0.647850067806844 and parameters: {'n_estimators': 56, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.13940869902497216}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:09,972] Trial 15 finished with value: 0.6597347147080951 and parameters: {'n_estimators': 193, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.07733686513855396}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:13,825] Trial 16 finished with value: 0.6609303194828471 and parameters: {'n_estimators': 196, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.05658517391771657}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[I 2023-10-29 11:28:15,572] Trial 17 finished with value: 0.6463401076283898 and parameters: {'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 7, 'min_weight_fraction_leaf': 0.17552856901158412}. Best is trial 10 with value: 0.6650653389623397.\n",
      "[W 2023-10-29 11:28:15,734] Trial 18 failed with parameters: {'n_estimators': 195, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.04704791127907297} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/ty/2g_hgfks4nl_84mz496fmn600000gn/T/ipykernel_8247/3935497687.py\", line 25, in objective\n",
      "    scores = cross_val_score(clf, X_train_del, y_train, cv=5, scoring='roc_auc')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\", line 473, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 1061, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 938, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\", line 451, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-29 11:28:15,736] Trial 18 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb Cellule 172\u001b[0m line \u001b[0;36m3\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Création de l'étude Optuna\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Affichage des meilleurs hyperparamètres et de la meilleure ROC AUC moyenne\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n",
      "\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n",
      "\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n",
      "\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n",
      "\u001b[1;32m    351\u001b[0m \n",
      "\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n",
      "\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 442\u001b[0m     _optimize(\n",
      "\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n",
      "\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n",
      "\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n",
      "\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n",
      "\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n",
      "\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n",
      "\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n",
      "\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n",
      "\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n",
      "\u001b[1;32m    452\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n",
      "\u001b[1;32m     67\u001b[0m             study,\n",
      "\u001b[1;32m     68\u001b[0m             func,\n",
      "\u001b[1;32m     69\u001b[0m             n_trials,\n",
      "\u001b[1;32m     70\u001b[0m             timeout,\n",
      "\u001b[1;32m     71\u001b[0m             catch,\n",
      "\u001b[1;32m     72\u001b[0m             callbacks,\n",
      "\u001b[1;32m     73\u001b[0m             gc_after_trial,\n",
      "\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n",
      "\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n",
      "\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n",
      "\u001b[1;32m     77\u001b[0m         )\n",
      "\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n",
      "\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n",
      "\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n",
      "\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n",
      "\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n",
      "\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n",
      "\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n",
      "\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n",
      "\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n",
      "\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n",
      "\u001b[1;32m    250\u001b[0m ):\n",
      "\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n",
      "\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n",
      "\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n",
      "\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n",
      "\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\n",
      "\u001b[1;32m/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb Cellule 172\u001b[0m line \u001b[0;36m2\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators,\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                               max_depth\u001b[39m=\u001b[39mmax_depth,\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                               min_samples_split\u001b[39m=\u001b[39mmin_samples_split,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                               class_weight \u001b[39m=\u001b[39m class_weights, \n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                               n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Évaluation à l'aide de la validation croisée avec ROC AUC comme métrique\u001b[39;00m\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(clf, X_train_del, y_train, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oussa/Desktop/Github/DS_Valeo_challenge/ValeoML.ipynb#Y333sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mmean()\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n",
      "\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n",
      "\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n",
      "\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n",
      "\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n",
      "\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n",
      "\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n",
      "\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n",
      "\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n",
      "\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n",
      "\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n",
      "\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n",
      "\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n",
      "\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n",
      "\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n",
      "\u001b[1;32m    527\u001b[0m )\n",
      "\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n",
      "\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n",
      "\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n",
      "\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n",
      "\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n",
      "\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[1;32m    268\u001b[0m         clone(estimator),\n",
      "\u001b[1;32m    269\u001b[0m         X,\n",
      "\u001b[1;32m    270\u001b[0m         y,\n",
      "\u001b[1;32m    271\u001b[0m         scorers,\n",
      "\u001b[1;32m    272\u001b[0m         train,\n",
      "\u001b[1;32m    273\u001b[0m         test,\n",
      "\u001b[1;32m    274\u001b[0m         verbose,\n",
      "\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n",
      "\u001b[1;32m    276\u001b[0m         fit_params,\n",
      "\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n",
      "\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n",
      "\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n",
      "\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n",
      "\u001b[1;32m    281\u001b[0m     )\n",
      "\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n",
      "\u001b[1;32m    283\u001b[0m )\n",
      "\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n",
      "\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n",
      "\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n",
      "\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n",
      "\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n",
      "\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n",
      "\u001b[1;32m     62\u001b[0m )\n",
      "\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n",
      "\u001b[1;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n",
      "\u001b[1;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n",
      "\u001b[1;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n",
      "\u001b[1;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n",
      "\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n",
      "\u001b[1;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n",
      "\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "\u001b[1;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n",
      "\u001b[0;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n",
      "\u001b[1;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n",
      "\u001b[1;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n",
      "\u001b[1;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n",
      "\u001b[1;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n",
      "\u001b[1;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n",
      "\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n",
      "\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n",
      "\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n",
      "\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n",
      "\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n",
      "\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n",
      "\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n",
      "\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n",
      "\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n",
      "\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n",
      "\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n",
      "\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n",
      "\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n",
      "\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n",
      "\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n",
      "\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n",
      "\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n",
      "\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n",
      "\u001b[1;32m    465\u001b[0m ]\n",
      "\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n",
      "\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n",
      "\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n",
      "\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n",
      "\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n",
      "\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n",
      "\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n",
      "\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n",
      "\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n",
      "\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n",
      "\u001b[1;32m    477\u001b[0m )(\n",
      "\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m    479\u001b[0m         t,\n",
      "\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n",
      "\u001b[1;32m    481\u001b[0m         X,\n",
      "\u001b[1;32m    482\u001b[0m         y,\n",
      "\u001b[1;32m    483\u001b[0m         sample_weight,\n",
      "\u001b[1;32m    484\u001b[0m         i,\n",
      "\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n",
      "\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n",
      "\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n",
      "\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n",
      "\u001b[1;32m    489\u001b[0m     )\n",
      "\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n",
      "\u001b[1;32m    491\u001b[0m )\n",
      "\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n",
      "\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n",
      "\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n",
      "\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n",
      "\u001b[1;32m     62\u001b[0m )\n",
      "\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n",
      "\u001b[0;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n",
      "\u001b[1;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n",
      "\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "\u001b[0;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n",
      "\u001b[1;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n",
      "\u001b[1;32m    539\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n",
      "\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n",
      "\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n",
      "\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n",
      "\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n",
      "\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Créer un objet Optuna Study\n",
    "study = create_study(direction=\"maximize\")\n",
    "\n",
    "class_weights = {0: 1, 1: 1}\n",
    "\n",
    "# Définition de l'espace de recherche\n",
    "def objective(trial: Trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 400)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    min_weight_fraction_leaf = trial.suggest_uniform('min_weight_fraction_leaf', 0.0, 0.5)\n",
    "\n",
    "\n",
    "    # Créer un modèle RandomForestClassifier avec les paramètres suggérés\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  min_samples_split=min_samples_split,\n",
    "                                  min_samples_leaf=min_samples_leaf,\n",
    "                                  min_weight_fraction_leaf= min_weight_fraction_leaf,\n",
    "                                  class_weight = class_weights, \n",
    "                                  n_jobs = -1)\n",
    "    \n",
    "    # Évaluation à l'aide de la validation croisée avec ROC AUC comme métrique\n",
    "    scores = cross_val_score(clf, X_train_del, y_train, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Création de l'étude Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# Affichage des meilleurs hyperparamètres et de la meilleure ROC AUC moyenne\n",
    "best_params = study.best_params\n",
    "best_auc = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669919158907615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0.6175360957633901,
          0.6431277883468068,
          0.6403687925589776,
          0.6601674325884963,
          0.6626046453678102,
          0.5346282124390818,
          0.6104793919906459,
          0.6627838662839454,
          0.6628432871224501,
          0.6382260483704794,
          0.6625083261053953,
          0.6551411005314332,
          0.655027050857529,
          0.6568753264552116,
          0.6581811473013834,
          0.6404370786032269,
          0.6599747940636665,
          0.6593158936366991,
          0.6466142102060083,
          0.6616452863461454,
          0.6439965785097829,
          0.6437311015377538,
          0.6589749426157627,
          0.6585999683727796,
          0.6543408360128617,
          0.6589833286211969,
          0.6607774545837906,
          0.6540523574259276,
          0.6570257953527154,
          0.6484433177912698,
          0.6398131597989276,
          0.6547505522783579,
          0.6280864093999933,
          0.6627843454842559,
          0.644346634336619,
          0.655217293380806,
          0.6586871828292945,
          0.6586565140094212,
          0.6362680359016872,
          0.6600457157096239,
          0.6692013168424532,
          0.6644725681782242,
          0.6624858036908008,
          0.6659106483101002,
          0.6630996592885793,
          0.6607352849564647,
          0.6458350305010998,
          0.661874344094575,
          0.660357195911463,
          0.6635429195758119,
          0.6575502800925814,
          0.6611641692343817,
          0.6584346442656496,
          0.6637657477202045,
          0.6610851011831456,
          0.6429569534361057,
          0.6566251838931192,
          0.6614631902281473,
          0.6662029604995183,
          0.6537677124414776,
          0.6541908463156684,
          0.6570401713620311,
          0.6607721833803748,
          0.6637096812838734,
          0.6608383130232269,
          0.6611531476272396,
          0.6609715307095518,
          0.6366698453620598,
          0.6588870093587821,
          0.6629391271845545,
          0.6660457827976671,
          0.6619529329455006,
          0.6642952640633311,
          0.6674536733099803,
          0.6625356405230951,
          0.6556286868473891,
          0.658132987670176,
          0.6656897369669496,
          0.660621714482871,
          0.6597510075186529,
          0.6491050934201006,
          0.6587121012454416,
          0.6612916365169805,
          0.6594649249332714,
          0.6553284678528473,
          0.6655296840632353,
          0.6560642799296534,
          0.6623243131861549,
          0.6628610175339393,
          0.6613040957250539,
          0.6292086965272353,
          0.6635141675571805,
          0.6613088877281593,
          0.6600025876816767,
          0.6602570430465639,
          0.652951634312659,
          0.6643302456859992,
          0.6674455269047015,
          0.6610491611598565,
          0.6552216061836008,
          0.6565676798558566,
          0.666501981493284,
          0.6632309601736622,
          0.6579535271538857,
          0.6579611943588539,
          0.6625471413305475,
          0.6641999032015373,
          0.6605392920294613,
          0.6606840105232388,
          0.6654860768349777,
          0.6547946387069259,
          0.6633042778211721,
          0.6627297166488564,
          0.6440926581720425,
          0.6590604798711908,
          0.6618508632793595,
          0.6617068635860475,
          0.6573947795918171,
          0.6643896665245039,
          0.6611301460123346,
          0.6626952142264988,
          0.6619107633181746,
          0.6667813552743181,
          0.6633478850494294,
          0.6627277998476143,
          0.6597859891413209,
          0.6584068506476393,
          0.6633033194205509,
          0.6626070413693628,
          0.6644117097387878,
          0.6623458772001285,
          0.6588606533417034,
          0.6561287323714187,
          0.6631332033103158,
          0.66043722236332,
          0.6284355068262084,
          0.661843196074391,
          0.6309913216823764,
          0.6630098092303564,
          0.6674301924947648,
          0.6654654712216252,
          0.6617023111830976,
          0.6626190213771259,
          0.6668585065243122,
          0.6598655363928676,
          0.6605335416257351,
          0.6553859718901098,
          0.660589608062066,
          0.6656935705694338,
          0.6679472496298178,
          0.6612748645061122,
          0.6628183687063028,
          0.661477566237463,
          0.6697102275722274,
          0.6575414148868368,
          0.6636416348397793,
          0.6514469453376205,
          0.6627680526736981,
          0.6470406984823726,
          0.6613213469362328,
          0.664304368869231,
          0.6606911985278966,
          0.6399799215069891,
          0.6632606705929146,
          0.6568139888154649,
          0.6530628087847001,
          0.6555158351742612,
          0.6607132417421806,
          0.6614413866140183,
          0.6524568599920453,
          0.6355149726137023,
          0.6646891667185801,
          0.6634897283413439,
          0.6654079671843627,
          0.6493168999573513,
          0.6316133236854338,
          0.6641313775571327,
          0.6682017049947049,
          0.6588261509193457,
          0.6310509821210364,
          0.6567066479459077,
          0.6604607031785357,
          0.6636876380695894,
          0.6580733272315161,
          0.6632707337994356,
          0.6665700279373781,
          0.6520799689478198,
          0.6615815527048461,
          0.6640460799018597,
          0.6559897642813672,
          0.6533062425424452,
          0.6636737412605844,
          0.6654865560352883,
          0.6599599388540404,
          0.6655483728753456,
          0.6614320422079634,
          0.6525376052443682,
          0.6615849071070199,
          0.6562140300266914,
          0.6584830434970123,
          0.6624872412917323,
          0.6670449154451052,
          0.6525198748328789,
          0.6607956641955903,
          0.662204992308835,
          0.6063736037300952,
          0.6663160517728015,
          0.660412303947173,
          0.6621460506706408,
          0.6596618762608959,
          0.6579425055467436,
          0.6615168606629258,
          0.6608924626583157,
          0.6323287697490428,
          0.6620861506318256,
          0.6428081617396888,
          0.6629472735898332,
          0.6612302988772337,
          0.6625433077280632,
          0.6568484912378223,
          0.6640494343040334,
          0.6589392421926289,
          0.6651012789856289,
          0.6615192566644783,
          0.6470713673022461,
          0.661216881268539,
          0.6604554319751199,
          0.6502199529425295,
          0.65423828714641,
          0.6609446954921626,
          0.6592756408106152,
          0.6605958376661027,
          0.6659211907169315,
          0.6649359548784987,
          0.660907317867942,
          0.6645319890167288,
          0.6685275612058597,
          0.6555745372123002,
          0.6556399480546864,
          0.6523389767156569,
          0.664019723884781,
          0.6619548497467427,
          0.6642161960120949,
          0.6581265184659839,
          0.6630042984267854,
          0.6640312246922336,
          0.6650332325415347,
          0.6550447812690182,
          0.6641778599872533,
          0.6368842875010182,
          0.6647433163536691,
          0.6370728528232087,
          0.664612973869207,
          0.6384706801290007,
          0.6358954576602566,
          0.6650897781781763,
          0.6617147703911712,
          0.659744777914616,
          0.6626655038072464,
          0.6663575025996618,
          0.654345628015967,
          0.6671757371298777,
          0.6609629051039625,
          0.6542488295532415,
          0.6624316540557118,
          0.6635510659810908,
          0.6640997503366382,
          0.6623918804299386,
          0.641558407329848,
          0.6477705205552973,
          0.669919158907615,
          0.660028464498445,
          0.6580920160436265,
          0.6599599388540405,
          0.6582568609504458,
          0.6644572337682875,
          0.66267796301532,
          0.6584753762920437,
          0.662975546408154,
          0.6233835375525323,
          0.6553370934584365,
          0.66166780876074,
          0.6633478850494294,
          0.6499106291420877,
          0.6663725974094431,
          0.6423926950704664,
          0.6547342594678001,
          0.6604918511987196,
          0.6596906282795272,
          0.6642406352279316,
          0.6596978162841849,
          0.6573482971616965,
          0.6385341741701448,
          0.6520457061256175,
          0.6622193683181508,
          0.5352696220547151,
          0.6520957825580671,
          0.6567430671695076,
          0.655062032480197,
          0.594593662096693
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0.6175360957633901,
          0.6431277883468068,
          0.6431277883468068,
          0.6601674325884963,
          0.6626046453678102,
          0.6626046453678102,
          0.6626046453678102,
          0.6627838662839454,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6628432871224501,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6692013168424532,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.6697102275722274,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615,
          0.669919158907615
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
