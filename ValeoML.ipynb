{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_x = pd.read_csv('traininginputs.csv')\n",
    "data_y = pd.read_csv('trainingoutput.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data_x, data_y, on='PROC_TRACEINFO', how ='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous explorant notre base de donnée afin de se faire une idée sur son contenu. Pour cela commencons par voir les dimensions de notre dataset (nombre d'observations et de variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr de lignes : 34515\n",
      "Nbr de colonnes : 15\n"
     ]
    }
   ],
   "source": [
    "nbr_lignes, nbr_colonnes = data.shape\n",
    "print(\"Nbr de lignes :\", nbr_lignes )\n",
    "print(\"Nbr de colonnes :\",nbr_colonnes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc 14 variables pour 34.515 individus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions s'il y a des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROC_TRACEINFO                         0\n",
       "OP070_V_1_angle_value                  0\n",
       "OP090_SnapRingPeakForce_value          0\n",
       "OP070_V_2_angle_value                  0\n",
       "OP120_Rodage_I_mesure_value            0\n",
       "OP090_SnapRingFinalStroke_value        0\n",
       "OP110_Vissage_M8_torque_value          0\n",
       "OP100_Capuchon_insertion_mesure    18627\n",
       "OP120_Rodage_U_mesure_value            0\n",
       "OP070_V_1_torque_value                 0\n",
       "OP090_StartLinePeakForce_value         0\n",
       "OP110_Vissage_M8_angle_value           0\n",
       "OP090_SnapRingMidPointForce_val        0\n",
       "OP070_V_2_torque_value                 0\n",
       "Binar OP130_Resultat_Global_v          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait que la variable 'OP100_Capuchon_insertion_mesure' compte 18.627 valeurs manquantes soit pour 53% des observations. Dans ce cas il serait difficile et pas pertinant de remplacer ces valeurs manquantes. Deux options s'offrirons a nous : utiliser des modèles qui gèrent les valeurs manquantes ou tout simplement supprimer cette variable. Les deux options seront explorées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROC_TRACEINFO                      object\n",
      "OP070_V_1_angle_value              float64\n",
      "OP090_SnapRingPeakForce_value      float64\n",
      "OP070_V_2_angle_value              float64\n",
      "OP120_Rodage_I_mesure_value        float64\n",
      "OP090_SnapRingFinalStroke_value    float64\n",
      "OP110_Vissage_M8_torque_value      float64\n",
      "OP100_Capuchon_insertion_mesure    float64\n",
      "OP120_Rodage_U_mesure_value        float64\n",
      "OP070_V_1_torque_value             float64\n",
      "OP090_StartLinePeakForce_value     float64\n",
      "OP110_Vissage_M8_angle_value       float64\n",
      "OP090_SnapRingMidPointForce_val    float64\n",
      "OP070_V_2_torque_value             float64\n",
      "Binar OP130_Resultat_Global_v        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "type_col = data.dtypes\n",
    "print(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable PROC_TRACEINFO est sous format 'object' et n a aucun interet. L énnoncé confirme qu il s agit Id de pieces. Nous décidons donc de la supprimer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('PROC_TRACEINFO', axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK toutes les variables sont quantitatives. \n",
    "Par contre notre prédicteur (Binar OP130_Resultat_Global_v) devrait etre une variable catégorielle a deux modalités et non une variable continue. Nous procédons donc au changement de son type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n"
     ]
    }
   ],
   "source": [
    "data['Binar OP130_Resultat_Global_v'] = data['Binar OP130_Resultat_Global_v'].astype('category')\n",
    "print(data['Binar OP130_Resultat_Global_v'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de donnée est un travail déterminant pour la bonne compréhension de nos données et permet parfois de mieux aiguiller le travail de modélisation. L'analyse de données permet d'étudier aussi bien la relation entre les différentes variables mais aussi de se faire une idée sur la population (exemple son homogénéité). Dans le cas ou l'on a une population hétérogène, il serait pertinant de créer plusieurs groupes d'observations, dans ce cas deux solutions sont envisageables : développer un modèle par groupe homoène d'invidus , ou encore rajouter une variable dans notre base de donnée qui porterait le groupe auquel appartiendrait chaque observation. L'inconvénient de cette stratégie est que pour chaque nouvelle observation , il faudra tout d'abord déterminer le groupe auquel elle appartient avant de l'intégrer dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OP070_V_1_angle_value  OP090_SnapRingPeakForce_value  \\\n",
      "count           34515.000000                   34515.000000   \n",
      "mean              159.906922                     156.915055   \n",
      "std                15.662650                      11.271492   \n",
      "min               101.800000                       0.000000   \n",
      "25%               148.700000                     149.210000   \n",
      "50%               158.000000                     156.180000   \n",
      "75%               169.300000                     164.380000   \n",
      "max               198.300000                     196.920000   \n",
      "\n",
      "       OP070_V_2_angle_value  OP120_Rodage_I_mesure_value  \\\n",
      "count           34515.000000                 34515.000000   \n",
      "mean              159.618236                   113.350222   \n",
      "std                15.091490                     3.528522   \n",
      "min                82.000000                    99.990000   \n",
      "25%               149.400000                   111.040000   \n",
      "50%               158.700000                   113.160000   \n",
      "75%               168.900000                   115.380000   \n",
      "max               198.100000                   177.950000   \n",
      "\n",
      "       OP090_SnapRingFinalStroke_value  OP110_Vissage_M8_torque_value  \\\n",
      "count                     34515.000000                   34515.000000   \n",
      "mean                         11.970190                      12.256785   \n",
      "std                           0.169873                       0.065319   \n",
      "min                           0.000000                      12.030000   \n",
      "25%                          11.850000                      12.210000   \n",
      "50%                          12.040000                      12.260000   \n",
      "75%                          12.080000                      12.300000   \n",
      "max                          12.190000                      12.500000   \n",
      "\n",
      "       OP100_Capuchon_insertion_mesure  OP120_Rodage_U_mesure_value  \\\n",
      "count                     15888.000000                 34515.000000   \n",
      "mean                          0.388173                    11.971027   \n",
      "std                           0.024425                     0.003050   \n",
      "min                           0.240000                    11.970000   \n",
      "25%                           0.380000                    11.970000   \n",
      "50%                           0.390000                    11.970000   \n",
      "75%                           0.410000                    11.970000   \n",
      "max                           0.420000                    11.990000   \n",
      "\n",
      "       OP070_V_1_torque_value  OP090_StartLinePeakForce_value  \\\n",
      "count            34515.000000                    34515.000000   \n",
      "mean                 6.548403                       23.630152   \n",
      "std                  0.097602                        2.546341   \n",
      "min                  5.670000                        0.000000   \n",
      "25%                  6.410000                       22.280000   \n",
      "50%                  6.610000                       23.880000   \n",
      "75%                  6.620000                       25.290000   \n",
      "max                  6.670000                       43.410000   \n",
      "\n",
      "       OP110_Vissage_M8_angle_value  OP090_SnapRingMidPointForce_val  \\\n",
      "count                  34515.000000                     34515.000000   \n",
      "mean                      17.878398                        97.700978   \n",
      "std                        6.785079                         6.837714   \n",
      "min                        6.300000                         0.000000   \n",
      "25%                       13.500000                        94.310000   \n",
      "50%                       16.400000                        98.500000   \n",
      "75%                       20.200000                       102.230000   \n",
      "max                       84.600000                       127.300000   \n",
      "\n",
      "       OP070_V_2_torque_value  \n",
      "count            34515.000000  \n",
      "mean                 6.550867  \n",
      "std                  0.094814  \n",
      "min                  5.740000  \n",
      "25%                  6.420000  \n",
      "50%                  6.610000  \n",
      "75%                  6.610000  \n",
      "max                  6.670000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contenu de la présence de valeurs manquantes dans l une de nos varibles nous décidons de partir un XGboost directement en premier essai car il intégre la possibilité de gestion de valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. ML modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Diviser les données en train/test et définition des paramètres de la Validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparer les données en prédicteur (y) / variables prédictives (X) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Binar OP130_Resultat_Global_v']\n",
    "X = data.drop('Binar OP130_Resultat_Global_v', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous séparons notre dataset en train/test en choisissant d'allouer 20% aux données test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y,test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Définition du modèle XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_jobs = -1, #utilise tous les coeurs CPU\n",
    "    booster = 'gbtree',  # utilise les arbres de décision pour construire l'ensemble\n",
    "    objective = 'binary:logistic', #classification a 2 classes (binaire)\n",
    "    eval_metric = 'auc', \n",
    "    enable_categorical = True, \n",
    "    verbosity = 1 # printing messages , 0 (silent), 1 (warning), 2 (info), and 3 (debug). \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost, en tant qu'algorithme de boosting basé sur des arbres de décision, n'a  pas besoin de centrer ou de réduire les données en amont. Nous procédons donc au paramètrage de notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme évoqué précédemment, XGBoost est capable de gérer les valeurs manquantes automatiquement. Aucune configuration ne sera donc necessaire pour la gestion des valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Recherche d'hyperparamètres\n",
    "\n",
    "Il existe deux types de paramètres en XGBoost : les paramètres intervenant lors du calcul du gain ou interet d ajouter un nouvel étage et donc infulancant la structure de l arbre  & ceux impactant le calcul du poids optimal a chaque feuille d abre impact donc directement les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 1: Recherche avec Grille (avec GridSearchCV)\n",
    "\n",
    "GridSearchCV effectue une recherche exhaustive à travers toutes les combinaisons possibles d'hyperparamètres spécifiées. Il parcourt chaque combinaison dans une grille prédéfinie, ce qui signifie qu'il teste toutes les valeurs d'hyperparamètres pour chaque hyperparamètre, ce qui peut être très coûteux en termes de calcul. Dans ce cas, nous nous contentons de selectionner aléatoirement quelques valeurs:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spécifiez la grille des hyperparamètres à explorer\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.05 ,0.06], # fraction de la correction appliquée\n",
    "    'n_estimators': [50, 100, 120], # nombre d arbres a entrainer séquentiellement pour faire prédicteur final (biais /variance)\n",
    "    'max_depth': [3, 4, 5], #profondeur maximale de ce que peut atteindre un arbre et donc des valeurs qu'il peut prendre soit 2^max_depth\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [ 0.1, 0.2], #définit le seuil du gain qu'apporte l'ajou de chaque nouveau noeud (0 -> pas de seuil)\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 0.7],\n",
    "}\n",
    "\n",
    "# Créez un objet GridSearchCV pour la recherche par grille\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=5, verbose=10, n_jobs=-1)\n",
    "\n",
    "# Entraînez le modèle en utilisant la recherche par grille\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Affichez les meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7066849126907246\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_ #enregistre les meilleurs paramètres trouvés.\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)  # Remplacez XGBClassifier par le modèle que vous utilisez\n",
    "\n",
    "best_model.fit(X_train, y_train) #entrainer le modèle avec les meilleurs paramètres trouvés.\n",
    "\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # prédire sur la partie X_test par vos données de test\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # Remplacez y_test par vos étiquettes de test\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette approche nous arrivons au score 0.70 ROC_AUC ce qui est suppérieur au score de 0.675 obtenu par Valéo en utilisant une   classification naïve bayésienne. \n",
    "\n",
    "Pour l'obtention de ce score, les meilleurs hyperparamètres sont :  {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.06, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
    "\n",
    "Néanmoins, l'inconvénient de l'approche est qu'il est très probable quelle soit biaisée par l'invention de l'humain. Le champs des paramètres possibles étant très large , le risque de tomber sur un 'minimal local' est donc très important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 2 : Recherche aléatoire (avec RandomizedSearchCV)\n",
    "\n",
    "Randomized Search sélectionne aléatoirement un nombre spécifié de combinaisons d'hyperparamètres à partir de l'espace d'hyperparamètres. Il effectue une recherche aléatoire parmi un sous-ensemble d'hyperparamètres, ce qui peut être plus efficace que Grid Search en termes de temps de calcul.\n",
    "\n",
    "L'approche est de définir un nombre fixe de combinaison a tester , RandomizedSearchCV selectionne aléatoirement les valeurs pour chaque hyperparamètre a chaque itération. Cette approche a plusieurs avantanges : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = { #définition de l espace de recherche  \n",
    "    'max_depth': range(3, 10),\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    'n_estimators': range(50, 200),\n",
    "    'subsample': [0.5, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.8, 1.0],\n",
    "    'min_child_weight': range(1, 10),\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5000,  # Nombre d'itérations d'optimisation\n",
    "    cv=5,  # Nombre pour la validation croisée\n",
    "    scoring='roc_auc',  # Métrique de performance (ROC AUC)\n",
    "    verbose=2,  # Afficher des détails pendant la recherche\n",
    "    n_jobs=-1,  # Utiliser tous les cœurs du CPU\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Exécuter la recherche d'hyperparamètres\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres: {'subsample': 1.0, 'n_estimators': 84, 'min_child_weight': 5, 'max_depth': 9, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
      "Best score = 0.658 after 5000 runs\n"
     ]
    }
   ],
   "source": [
    "# Afficher les meilleurs hyperparamètres trouvés\n",
    "best_params = random_search.best_params_\n",
    "print(\"Meilleurs hyperparamètres:\", best_params)\n",
    "print(\"Best score = %.3f after %d runs\" % (random_search.best_score_, random_search.n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score = 0.662 after 2000 runs\n",
    "\n",
    "Best score = 0.662 after 4000 runs\n",
    "\n",
    "Best score = 0.658 after 4000 runs\n",
    "\n",
    "Best score = 0.658 after 5000 runs 23min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 3: Processus bayesien (BayesSearchCV de Scikit-optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’idée  de l’optimisation bayésienne est de minimiser le nombre d’observations tout en convergeant rapidement vers la solution optimale. Concrétement l'algorithme déterminerait la prochaine configuration ayant le plus de potentiel à tester en fonction des résultats des itérations précédentes en fonction un processus gaussien.\n",
    "\n",
    "Pour cela, il convient de connaître trois principes fondamentaux:\n",
    "- Le processus Gaussien : d’exploiter les observations connues pour en déduire des probabilités d’événement qui n’ont pas encore été observées. Pour cela, il convient de déterminer pour chaque valeur X la distribution de probabilité. Le processus n'est pas applicable a toutes les observations a cause des limites de capacités calculatoires.\n",
    "\n",
    "- Déterminer les points à plus fort potentiel avec la fonction d’acquisition : gagner en connaissance sur le comportement de la fonction et donc choisir une zone de l’espace de recherche où l’inconnu est grand : c’est l’exploration. D’autre part, nous souhaitons trouver le point qui minimise/maximise notre fonction : c’est l’exploitation. Ce compromis entre exploration et exploitation est exprimé par une fonction d’acquisition\n",
    "\n",
    "- La fonction d’acquisition : Deux raisons permettent à une configuration donnée d’augmenter son potentiel, soit être dans une région loin de toutes configurations testées précédemment ou être dans une région près d’une configuration performante. En combinant ces deux critères, l’optimisation bayésienne cherche à réduire l’incertitude en explorant les régions peu explorées tout en exploitant les régions près d’une configuration performante. C’est ce qu’on appelle une fonction d’acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space\n",
    "search_spaces = {\n",
    "     'learning_rate': np.arange(0.01, 1.0),\n",
    "     'max_depth': np.arange(2, 20),\n",
    "     'reg_lambda': np.arange(1e-9, 100),\n",
    "     'reg_alpha': np.arange(1e-9, 100),\n",
    "     'gamma': np.arange(1e-9, 0.5),  \n",
    "     'n_estimators': np.arange(10, 5000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bayesian CV for HP optimization\n",
    "bayes_cv = BayesSearchCV(\n",
    "                    estimator = model,                                    \n",
    "                    search_spaces = search_spaces,                      \n",
    "                    scoring = 'roc_auc',                                  \n",
    "                    cv = 5,                                   \n",
    "                    n_iter = 20,                                      \n",
    "                    n_points = 5,                                       \n",
    "                    n_jobs = -1,                                        \n",
    "                    refit=False,\n",
    "                    verbose = 1,\n",
    "                    random_state=42\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "CPU times: user 46.1 s, sys: 9.92 s, total: 56 s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, device=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=True,\n",
       "                                      eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "                                      gamma=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=...\n",
       "       5.6e+01, 5.7e+01, 5.8e+01, 5.9e+01, 6.0e+01, 6.1e+01, 6.2e+01,\n",
       "       6.3e+01, 6.4e+01, 6.5e+01, 6.6e+01, 6.7e+01, 6.8e+01, 6.9e+01,\n",
       "       7.0e+01, 7.1e+01, 7.2e+01, 7.3e+01, 7.4e+01, 7.5e+01, 7.6e+01,\n",
       "       7.7e+01, 7.8e+01, 7.9e+01, 8.0e+01, 8.1e+01, 8.2e+01, 8.3e+01,\n",
       "       8.4e+01, 8.5e+01, 8.6e+01, 8.7e+01, 8.8e+01, 8.9e+01, 9.0e+01,\n",
       "       9.1e+01, 9.2e+01, 9.3e+01, 9.4e+01, 9.5e+01, 9.6e+01, 9.7e+01,\n",
       "       9.8e+01, 9.9e+01])},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, device=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=True,\n",
       "                                      eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "                                      gamma=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=...\n",
       "       5.6e+01, 5.7e+01, 5.8e+01, 5.9e+01, 6.0e+01, 6.1e+01, 6.2e+01,\n",
       "       6.3e+01, 6.4e+01, 6.5e+01, 6.6e+01, 6.7e+01, 6.8e+01, 6.9e+01,\n",
       "       7.0e+01, 7.1e+01, 7.2e+01, 7.3e+01, 7.4e+01, 7.5e+01, 7.6e+01,\n",
       "       7.7e+01, 7.8e+01, 7.9e+01, 8.0e+01, 8.1e+01, 8.2e+01, 8.3e+01,\n",
       "       8.4e+01, 8.5e+01, 8.6e+01, 8.7e+01, 8.8e+01, 8.9e+01, 9.0e+01,\n",
       "       9.1e+01, 9.2e+01, 9.3e+01, 9.4e+01, 9.5e+01, 9.6e+01, 9.7e+01,\n",
       "       9.8e+01, 9.9e+01])},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster='gbtree',\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, device=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=True,\n",
       "                                      eval_metric='auc', feature_types=None,\n",
       "                                      gamma=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=...\n",
       "       5.6e+01, 5.7e+01, 5.8e+01, 5.9e+01, 6.0e+01, 6.1e+01, 6.2e+01,\n",
       "       6.3e+01, 6.4e+01, 6.5e+01, 6.6e+01, 6.7e+01, 6.8e+01, 6.9e+01,\n",
       "       7.0e+01, 7.1e+01, 7.2e+01, 7.3e+01, 7.4e+01, 7.5e+01, 7.6e+01,\n",
       "       7.7e+01, 7.8e+01, 7.9e+01, 8.0e+01, 8.1e+01, 8.2e+01, 8.3e+01,\n",
       "       8.4e+01, 8.5e+01, 8.6e+01, 8.7e+01, 8.8e+01, 8.9e+01, 9.0e+01,\n",
       "       9.1e+01, 9.2e+01, 9.3e+01, 9.4e+01, 9.5e+01, 9.6e+01, 9.7e+01,\n",
       "       9.8e+01, 9.9e+01])},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run bayesian CV\n",
    "%time bayes_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "Best score = 0.626 after 30 runs\n"
     ]
    }
   ],
   "source": [
    "# Show best params\n",
    "print('Best parameters:')\n",
    "print(\"Best score = %.3f after %d runs\" % (bayes_cv.best_score_, bayes_cv.n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score = 0.630 after 20 runs\n",
    "\n",
    "Best score = 0.638 after 300 runs - 35min 27s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 4: Approche 'HalvingRandomSearchCV' & 'HalvingGridSearchCV' ( to do)\n",
    "Permet d'explorer le champs des possibles sans forcément trouver la combinaison optimale. L'avantage que présente cette méthode est de pouvoir maitriser le temps de calcul.\n",
    "Chercher des paramètres sur des échantillons de plus en plus important en écartant a chaque itération la moitiée des combinaisons les moins performantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import HalvingGridSearchCV \n",
    "from sklearn.model_selection import HalvingRandomSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = { #définition de l espace de recherche  \n",
    "    'max_depth': range(3, 10),\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    'n_estimators': range(50, 200),\n",
    "    'subsample': [0.5, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halving_grid = HalvingGridSearchCV(model,\n",
    "                           param_grid= param_dist, \n",
    "                           cv=5, \n",
    "                           scoring='roc_auc',\n",
    "                           n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 27612 entries, 21140 to 15725\n",
      "Series name: Binar OP130_Resultat_Global_v\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "27612 non-null  category\n",
      "dtypes: category(1)\n",
      "memory usage: 242.8 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécuter la recherche d'hyperparamètres\n",
    "halving_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 5 : SMAC (Sequential Model-based Algorithm Configuration) - Forets aléatoires  (to do)\n",
    "\n",
    "SMAC est un framework d'optimisation basé sur des modèles séquentiels. Il est principalement utilisé pour automatiser la recherche des meilleurs hyperparamètres pour un algorithme d'apprentissage automatique donné. SMAC utilise des modèles statistiques pour modéliser la relation entre les hyperparamètres et la fonction de coût. Il recherche les hyperparamètres les plus prometteurs en utilisant une approche séquentielle, en essayant de minimiser la fonction de coût prédite par le modèle.\n",
    "SMAC équilibre l'exploitation (exploration des valeurs déjà connues prometteuses) et l'exploration (essai de nouvelles valeurs) pour rechercher efficacement l'espace des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 6: Hyperopt, Optuna, gpyopt (to do)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
