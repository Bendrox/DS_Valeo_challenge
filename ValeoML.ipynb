{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_x = pd.read_csv('traininginputs.csv')\n",
    "data_y = pd.read_csv('trainingoutput.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data_x, data_y, on='PROC_TRACEINFO', how ='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous explorant notre base de donnée afin de se faire une idée sur son contenu. Pour cela commencons par voir les dimensions de notre dataset (nombre d'observations et de variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr de lignes : 34515\n",
      "Nbr de colonnes : 15\n"
     ]
    }
   ],
   "source": [
    "nbr_lignes, nbr_colonnes = data.shape\n",
    "print(\"Nbr de lignes :\", nbr_lignes )\n",
    "print(\"Nbr de colonnes :\",nbr_colonnes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc 14 variables pour 34.515 individus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions s'il y a des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROC_TRACEINFO                         0\n",
       "OP070_V_1_angle_value                  0\n",
       "OP090_SnapRingPeakForce_value          0\n",
       "OP070_V_2_angle_value                  0\n",
       "OP120_Rodage_I_mesure_value            0\n",
       "OP090_SnapRingFinalStroke_value        0\n",
       "OP110_Vissage_M8_torque_value          0\n",
       "OP100_Capuchon_insertion_mesure    18627\n",
       "OP120_Rodage_U_mesure_value            0\n",
       "OP070_V_1_torque_value                 0\n",
       "OP090_StartLinePeakForce_value         0\n",
       "OP110_Vissage_M8_angle_value           0\n",
       "OP090_SnapRingMidPointForce_val        0\n",
       "OP070_V_2_torque_value                 0\n",
       "Binar OP130_Resultat_Global_v          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait que la variable 'OP100_Capuchon_insertion_mesure' compte 18.627 valeurs manquantes soit pour 53% des observations. Dans ce cas il serait difficile et pas pertinant de remplacer ces valeurs manquantes. Deux options s'offrirons a nous : utiliser des modèles qui gèrent les valeurs manquantes ou tout simplement supprimer cette variable. Les deux options seront explorées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROC_TRACEINFO                      object\n",
      "OP070_V_1_angle_value              float64\n",
      "OP090_SnapRingPeakForce_value      float64\n",
      "OP070_V_2_angle_value              float64\n",
      "OP120_Rodage_I_mesure_value        float64\n",
      "OP090_SnapRingFinalStroke_value    float64\n",
      "OP110_Vissage_M8_torque_value      float64\n",
      "OP100_Capuchon_insertion_mesure    float64\n",
      "OP120_Rodage_U_mesure_value        float64\n",
      "OP070_V_1_torque_value             float64\n",
      "OP090_StartLinePeakForce_value     float64\n",
      "OP110_Vissage_M8_angle_value       float64\n",
      "OP090_SnapRingMidPointForce_val    float64\n",
      "OP070_V_2_torque_value             float64\n",
      "Binar OP130_Resultat_Global_v        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "type_col = data.dtypes\n",
    "print(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable PROC_TRACEINFO est sous format 'object' et n a aucun interet. L énnoncé confirme qu il s agit Id de pieces. Nous décidons donc de la supprimer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('PROC_TRACEINFO', axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK toutes les variables sont quantitatives. \n",
    "Par contre notre prédicteur (Binar OP130_Resultat_Global_v) devrait etre une variable catégorielle a deux modalités et non une variable continue. Nous procédons donc au changement de son type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n"
     ]
    }
   ],
   "source": [
    "data['Binar OP130_Resultat_Global_v'] = data['Binar OP130_Resultat_Global_v'].astype('category')\n",
    "print(data['Binar OP130_Resultat_Global_v'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de donnée est un travail déterminant pour la bonne compréhension de nos données et permet parfois de mieux aiguiller le travail de modélisation. L'analyse de données permet d'étudier aussi bien la relation entre les différentes variables mais aussi de se faire une idée sur la population (exemple son homogénéité). Dans le cas ou l'on a une population hétérogène, il serait pertinant de créer plusieurs groupes d'observations, dans ce cas deux solutions sont envisageables : développer un modèle par groupe homoène d'invidus , ou encore rajouter une variable dans notre base de donnée qui porterait le groupe auquel appartiendrait chaque observation. L'inconvénient de cette stratégie est que pour chaque nouvelle observation , il faudra tout d'abord déterminer le groupe auquel elle appartient avant de l'intégrer dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OP070_V_1_angle_value  OP090_SnapRingPeakForce_value  \\\n",
      "count           34515.000000                   34515.000000   \n",
      "mean              159.906922                     156.915055   \n",
      "std                15.662650                      11.271492   \n",
      "min               101.800000                       0.000000   \n",
      "25%               148.700000                     149.210000   \n",
      "50%               158.000000                     156.180000   \n",
      "75%               169.300000                     164.380000   \n",
      "max               198.300000                     196.920000   \n",
      "\n",
      "       OP070_V_2_angle_value  OP120_Rodage_I_mesure_value  \\\n",
      "count           34515.000000                 34515.000000   \n",
      "mean              159.618236                   113.350222   \n",
      "std                15.091490                     3.528522   \n",
      "min                82.000000                    99.990000   \n",
      "25%               149.400000                   111.040000   \n",
      "50%               158.700000                   113.160000   \n",
      "75%               168.900000                   115.380000   \n",
      "max               198.100000                   177.950000   \n",
      "\n",
      "       OP090_SnapRingFinalStroke_value  OP110_Vissage_M8_torque_value  \\\n",
      "count                     34515.000000                   34515.000000   \n",
      "mean                         11.970190                      12.256785   \n",
      "std                           0.169873                       0.065319   \n",
      "min                           0.000000                      12.030000   \n",
      "25%                          11.850000                      12.210000   \n",
      "50%                          12.040000                      12.260000   \n",
      "75%                          12.080000                      12.300000   \n",
      "max                          12.190000                      12.500000   \n",
      "\n",
      "       OP100_Capuchon_insertion_mesure  OP120_Rodage_U_mesure_value  \\\n",
      "count                     15888.000000                 34515.000000   \n",
      "mean                          0.388173                    11.971027   \n",
      "std                           0.024425                     0.003050   \n",
      "min                           0.240000                    11.970000   \n",
      "25%                           0.380000                    11.970000   \n",
      "50%                           0.390000                    11.970000   \n",
      "75%                           0.410000                    11.970000   \n",
      "max                           0.420000                    11.990000   \n",
      "\n",
      "       OP070_V_1_torque_value  OP090_StartLinePeakForce_value  \\\n",
      "count            34515.000000                    34515.000000   \n",
      "mean                 6.548403                       23.630152   \n",
      "std                  0.097602                        2.546341   \n",
      "min                  5.670000                        0.000000   \n",
      "25%                  6.410000                       22.280000   \n",
      "50%                  6.610000                       23.880000   \n",
      "75%                  6.620000                       25.290000   \n",
      "max                  6.670000                       43.410000   \n",
      "\n",
      "       OP110_Vissage_M8_angle_value  OP090_SnapRingMidPointForce_val  \\\n",
      "count                  34515.000000                     34515.000000   \n",
      "mean                      17.878398                        97.700978   \n",
      "std                        6.785079                         6.837714   \n",
      "min                        6.300000                         0.000000   \n",
      "25%                       13.500000                        94.310000   \n",
      "50%                       16.400000                        98.500000   \n",
      "75%                       20.200000                       102.230000   \n",
      "max                       84.600000                       127.300000   \n",
      "\n",
      "       OP070_V_2_torque_value  \n",
      "count            34515.000000  \n",
      "mean                 6.550867  \n",
      "std                  0.094814  \n",
      "min                  5.740000  \n",
      "25%                  6.420000  \n",
      "50%                  6.610000  \n",
      "75%                  6.610000  \n",
      "max                  6.670000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contenu de la présence de valeurs manquantes dans l une de nos varibles nous décidons de partir un XGboost directement en premier essai car il intégre la possibilité de gestion de valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Equilibrage du prédicteur ( to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedKFold est une variation de la validation croisée k-fold qui garantit que chaque pli (fold) a une distribution similaire des classes (ou étiquettes) de la variable cible par rapport à l'ensemble de données d'origine. Cette technique est particulièrement utile lorsque vous travaillez avec des ensembles de données déséquilibrés, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. ML modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Diviser les données en train/test et définition des paramètres de la Validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparer les données en prédicteur (y) / variables prédictives (X) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Binar OP130_Resultat_Global_v']\n",
    "X = data.drop('Binar OP130_Resultat_Global_v', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous séparons notre dataset en train/test en choisissant d'allouer 20% aux données test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y,test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Définition du modèle XG Boost\n",
    "\n",
    "XGBoost, en tant qu'algorithme de boosting basé sur des arbres de décision, n'a  pas besoin de centrer ou de réduire les données en amont. Nous procédons donc au paramètrage de notre modèle. \n",
    "Comme évoqué précédemment, XGBoost est capable de gérer les valeurs manquantes automatiquement. Aucune configuration ne sera donc necessaire pour la gestion des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_jobs = -1, #utilise tous les coeurs CPU\n",
    "    booster = 'gbtree',  # utilise les arbres de décision pour construire l'ensemble\n",
    "    objective = 'binary:logistic', #classification a 2 classes (binaire)\n",
    "    eval_metric = 'auc', \n",
    "    enable_categorical = True, \n",
    "    verbosity = 1 # printing messages , 0 (silent), 1 (warning), 2 (info), and 3 (debug). \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Recherche d'hyperparamètres\n",
    "\n",
    "Il existe deux types de paramètres en XGBoost : les paramètres intervenant lors du calcul du gain ou interet d ajouter un nouvel étage et donc infulancant la structure de l arbre  & ceux impactant le calcul du poids optimal a chaque feuille d abre impact donc directement les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 1: Recherche avec Grille (avec GridSearchCV)\n",
    "\n",
    "GridSearchCV effectue une recherche exhaustive à travers toutes les combinaisons possibles d'hyperparamètres spécifiées. Il parcourt chaque combinaison dans une grille prédéfinie, ce qui signifie qu'il teste toutes les valeurs d'hyperparamètres pour chaque hyperparamètre, ce qui peut être très coûteux en termes de calcul. Dans ce cas, nous nous contentons de selectionner aléatoirement quelques valeurs:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "[CV 4/5; 1/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8\n",
      "[CV 1/5; 1/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8\n",
      "[CV 2/5; 2/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9\n",
      "[CV 2/5; 1/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8\n",
      "[CV 1/5; 2/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9\n",
      "[CV 3/5; 1/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8\n",
      "[CV 5/5; 1/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8\n",
      "[CV 3/5; 2/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9\n",
      "[CV 2/5; 2/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9;, score=0.673 total time=   0.1s\n",
      "[CV 4/5; 1/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8;, score=0.603 total time=   0.2s\n",
      "[CV 3/5; 1/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8;, score=0.636 total time=   0.1s\n",
      "[CV 2/5; 1/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8;, score=0.680 total time=   0.1s\n",
      "[CV 1/5; 1/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8;, score=0.634 total time=   0.2s\n",
      "[CV 1/5; 2/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9;, score=0.638 total time=   0.1s\n",
      "[CV 3/5; 2/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9;, score=0.619 total time=   0.1s\n",
      "[CV 5/5; 1/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.8;, score=0.646 total time=   0.1s\n",
      "[CV 4/5; 2/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9\n",
      "[CV 5/5; 2/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9\n",
      "[CV 1/5; 3/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 3/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 3/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 3/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 3/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 4/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8\n",
      "[CV 5/5; 2/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9;, score=0.639 total time=   0.1s\n",
      "[CV 1/5; 3/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.626 total time=   0.1s\n",
      "[CV 5/5; 3/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.611 total time=   0.1s\n",
      "[CV 2/5; 4/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8\n",
      "[CV 3/5; 4/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8\n",
      "[CV 4/5; 2/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=0.9;, score=0.605 total time=   0.1s\n",
      "[CV 4/5; 4/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8\n",
      "[CV 5/5; 4/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8\n",
      "[CV 2/5; 3/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.671 total time=   0.1s\n",
      "[CV 4/5; 3/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.606 total time=   0.1s\n",
      "[CV 1/5; 5/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9\n",
      "[CV 2/5; 5/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9\n",
      "[CV 3/5; 3/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.619 total time=   0.1s\n",
      "[CV 3/5; 5/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9\n",
      "[CV 1/5; 4/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.640 total time=   0.2s\n",
      "[CV 4/5; 5/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9\n",
      "[CV 2/5; 4/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.670 total time=   0.2s\n",
      "[CV 4/5; 4/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.600 total time=   0.2s\n",
      "[CV 3/5; 4/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.620 total time=   0.2s\n",
      "[CV 5/5; 5/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9\n",
      "[CV 1/5; 6/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 5/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9;, score=0.652 total time=   0.2s\n",
      "[CV 2/5; 6/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 6/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 5/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9;, score=0.668 total time=   0.2s\n",
      "[CV 3/5; 5/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9;, score=0.602 total time=   0.2s\n",
      "[CV 5/5; 6/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 6/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 4/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.657 total time=   0.2s\n",
      "[CV 1/5; 7/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8\n",
      "[CV 4/5; 5/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9;, score=0.601 total time=   0.2s\n",
      "[CV 2/5; 7/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8\n",
      "[CV 3/5; 6/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.614 total time=   0.2s\n",
      "[CV 1/5; 6/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.647 total time=   0.2s\n",
      "[CV 3/5; 7/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8\n",
      "[CV 4/5; 7/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8\n",
      "[CV 2/5; 6/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.687 total time=   0.2s\n",
      "[CV 5/5; 6/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.661 total time=   0.2s\n",
      "[CV 5/5; 7/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8\n",
      "[CV 1/5; 8/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9\n",
      "[CV 4/5; 6/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.619 total time=   0.2s\n",
      "[CV 1/5; 7/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8;, score=0.645 total time=   0.2s\n",
      "[CV 3/5; 8/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9\n",
      "[CV 2/5; 8/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9\n",
      "[CV 5/5; 5/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9;, score=0.641 total time=   0.3s\n",
      "[CV 4/5; 8/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9\n",
      "[CV 3/5; 7/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8;, score=0.618 total time=   0.2s\n",
      "[CV 5/5; 8/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9\n",
      "[CV 2/5; 7/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8;, score=0.658 total time=   0.3s\n",
      "[CV 1/5; 8/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9;, score=0.649 total time=   0.2s\n",
      "[CV 4/5; 7/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8;, score=0.599 total time=   0.2s\n",
      "[CV 1/5; 9/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0\n",
      "[CV 2/5; 9/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0\n",
      "[CV 5/5; 7/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.8;, score=0.648 total time=   0.2s\n",
      "[CV 2/5; 8/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9;, score=0.670 total time=   0.2s\n",
      "[CV 3/5; 9/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0\n",
      "[CV 4/5; 9/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0\n",
      "[CV 5/5; 9/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0\n",
      "[CV 3/5; 8/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9;, score=0.607 total time=   0.2s\n",
      "[CV 1/5; 10/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8\n",
      "[CV 4/5; 8/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9;, score=0.597 total time=   0.2s\n",
      "[CV 2/5; 10/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8\n",
      "[CV 5/5; 8/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=0.9;, score=0.637 total time=   0.2s\n",
      "[CV 3/5; 10/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8\n",
      "[CV 1/5; 9/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0;, score=0.652 total time=   0.2s\n",
      "[CV 2/5; 10/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8;, score=0.682 total time=   0.1s\n",
      "[CV 2/5; 9/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0;, score=0.683 total time=   0.2s\n",
      "[CV 1/5; 10/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8;, score=0.636 total time=   0.2s\n",
      "[CV 4/5; 10/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8\n",
      "[CV 5/5; 10/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8\n",
      "[CV 1/5; 11/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9\n",
      "[CV 3/5; 10/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8;, score=0.640 total time=   0.1s\n",
      "[CV 3/5; 9/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0;, score=0.622 total time=   0.2s\n",
      "[CV 2/5; 11/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9\n",
      "[CV 5/5; 9/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0;, score=0.660 total time=   0.2s\n",
      "[CV 4/5; 9/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1.0;, score=0.615 total time=   0.2s\n",
      "[CV 3/5; 11/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9\n",
      "[CV 4/5; 11/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9\n",
      "[CV 5/5; 11/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9\n",
      "[CV 1/5; 12/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 10/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8;, score=0.601 total time=   0.1s\n",
      "[CV 2/5; 12/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 10/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.8;, score=0.646 total time=   0.1s\n",
      "[CV 3/5; 12/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 11/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9;, score=0.634 total time=   0.1s\n",
      "[CV 4/5; 12/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 12/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0;, score=0.671 total time=   0.1s\n",
      "[CV 5/5; 12/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 11/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9;, score=0.672 total time=   0.2s\n",
      "[CV 1/5; 13/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8\n",
      "[CV 4/5; 11/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9;, score=0.603 total time=   0.1s\n",
      "[CV 3/5; 11/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9;, score=0.627 total time=   0.2s\n",
      "[CV 2/5; 13/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8\n",
      "[CV 3/5; 13/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8\n",
      "[CV 1/5; 12/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0;, score=0.628 total time=   0.2s\n",
      "[CV 4/5; 13/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8\n",
      "[CV 3/5; 12/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0;, score=0.618 total time=   0.1s\n",
      "[CV 5/5; 13/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8\n",
      "[CV 5/5; 12/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0;, score=0.612 total time=   0.1s\n",
      "[CV 1/5; 14/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9\n",
      "[CV 5/5; 11/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=0.9;, score=0.625 total time=   0.3s\n",
      "[CV 2/5; 13/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8;, score=0.669 total time=   0.2s\n",
      "[CV 2/5; 14/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9\n",
      "[CV 1/5; 13/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8;, score=0.636 total time=   0.2s\n",
      "[CV 3/5; 13/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8;, score=0.613 total time=   0.2s\n",
      "[CV 4/5; 12/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=50, subsample=1.0;, score=0.605 total time=   0.2s\n",
      "[CV 5/5; 13/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8;, score=0.660 total time=   0.2s\n",
      "[CV 3/5; 14/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9\n",
      "[CV 4/5; 13/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.8;, score=0.605 total time=   0.2s\n",
      "[CV 4/5; 14/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9\n",
      "[CV 5/5; 14/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9\n",
      "[CV 1/5; 14/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9;, score=0.642 total time=   0.2s\n",
      "[CV 1/5; 15/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 15/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 15/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 15/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 14/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9;, score=0.670 total time=   0.2s\n",
      "[CV 5/5; 15/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 14/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9;, score=0.609 total time=   0.2s\n",
      "[CV 5/5; 14/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9;, score=0.647 total time=   0.2s\n",
      "[CV 4/5; 14/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=0.9;, score=0.598 total time=   0.2s\n",
      "[CV 3/5; 15/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0;, score=0.605 total time=   0.2s\n",
      "[CV 1/5; 16/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8\n",
      "[CV 2/5; 15/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0;, score=0.681 total time=   0.2s\n",
      "[CV 4/5; 15/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0;, score=0.612 total time=   0.2s\n",
      "[CV 2/5; 16/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8\n",
      "[CV 3/5; 16/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8\n",
      "[CV 4/5; 16/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8\n",
      "[CV 5/5; 16/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8\n",
      "[CV 1/5; 15/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0;, score=0.642 total time=   0.2s\n",
      "[CV 1/5; 17/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9\n",
      "[CV 2/5; 17/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9\n",
      "[CV 5/5; 15/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100, subsample=1.0;, score=0.669 total time=   0.2s\n",
      "[CV 3/5; 17/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9\n",
      "[CV 3/5; 16/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8;, score=0.615 total time=   0.3s\n",
      "[CV 1/5; 16/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8;, score=0.639 total time=   0.3s\n",
      "[CV 4/5; 17/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9\n",
      "[CV 5/5; 17/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9\n",
      "[CV 4/5; 16/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8;, score=0.602 total time=   0.3s\n",
      "[CV 1/5; 17/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9;, score=0.641 total time=   0.3s\n",
      "[CV 2/5; 16/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8;, score=0.659 total time=   0.3s\n",
      "[CV 1/5; 18/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0\n",
      "[CV 2/5; 18/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0\n",
      "[CV 2/5; 17/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9;, score=0.674 total time=   0.3s\n",
      "[CV 5/5; 16/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.8;, score=0.647 total time=   0.3s\n",
      "[CV 3/5; 18/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0\n",
      "[CV 4/5; 18/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0\n",
      "[CV 5/5; 18/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0\n",
      "[CV 3/5; 17/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9;, score=0.610 total time=   0.3s\n",
      "[CV 5/5; 17/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9;, score=0.641 total time=   0.2s\n",
      "[CV 1/5; 19/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8\n",
      "[CV 2/5; 19/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8\n",
      "[CV 1/5; 18/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0;, score=0.649 total time=   0.2s\n",
      "[CV 3/5; 19/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8\n",
      "[CV 4/5; 17/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=0.9;, score=0.601 total time=   0.3s\n",
      "[CV 2/5; 18/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0;, score=0.675 total time=   0.2s\n",
      "[CV 5/5; 18/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0;, score=0.665 total time=   0.2s\n",
      "[CV 4/5; 18/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0;, score=0.614 total time=   0.2s\n",
      "[CV 4/5; 19/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8\n",
      "[CV 5/5; 19/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8\n",
      "[CV 3/5; 18/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=120, subsample=1.0;, score=0.611 total time=   0.3s\n",
      "[CV 1/5; 20/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9\n",
      "[CV 2/5; 20/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9\n",
      "[CV 2/5; 19/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8;, score=0.678 total time=   0.1s\n",
      "[CV 3/5; 20/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9\n",
      "[CV 3/5; 19/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8;, score=0.638 total time=   0.1s\n",
      "[CV 4/5; 20/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9\n",
      "[CV 1/5; 19/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8;, score=0.639 total time=   0.1s\n",
      "[CV 5/5; 20/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9\n",
      "[CV 1/5; 21/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 19/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8;, score=0.595 total time=   0.1s\n",
      "[CV 5/5; 19/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.8;, score=0.655 total time=   0.1s\n",
      "[CV 3/5; 21/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 21/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 20/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9;, score=0.633 total time=   0.1s\n",
      "[CV 4/5; 21/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 20/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9;, score=0.592 total time=   0.1s\n",
      "[CV 5/5; 21/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 20/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9;, score=0.675 total time=   0.1s\n",
      "[CV 1/5; 22/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8\n",
      "[CV 5/5; 20/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9;, score=0.632 total time=   0.1s\n",
      "[CV 2/5; 22/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8\n",
      "[CV 3/5; 20/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=0.9;, score=0.624 total time=   0.1s\n",
      "[CV 3/5; 22/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8\n",
      "[CV 1/5; 21/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0;, score=0.629 total time=   0.1s\n",
      "[CV 4/5; 22/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8\n",
      "[CV 5/5; 21/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0;, score=0.621 total time=   0.1s\n",
      "[CV 5/5; 22/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8\n",
      "[CV 2/5; 21/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0;, score=0.670 total time=   0.1s\n",
      "[CV 1/5; 23/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9\n",
      "[CV 3/5; 21/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0;, score=0.615 total time=   0.1s\n",
      "[CV 4/5; 21/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=50, subsample=1.0;, score=0.607 total time=   0.1s\n",
      "[CV 2/5; 23/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9\n",
      "[CV 3/5; 23/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9\n",
      "[CV 1/5; 22/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.636 total time=   0.2s\n",
      "[CV 4/5; 23/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9\n",
      "[CV 4/5; 22/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.604 total time=   0.2s\n",
      "[CV 2/5; 22/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.675 total time=   0.2s\n",
      "[CV 5/5; 23/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9\n",
      "[CV 3/5; 22/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.612 total time=   0.2s\n",
      "[CV 1/5; 24/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 24/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 22/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.659 total time=   0.2s\n",
      "[CV 3/5; 24/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 23/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9;, score=0.636 total time=   0.2s\n",
      "[CV 4/5; 24/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 23/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9;, score=0.605 total time=   0.2s\n",
      "[CV 5/5; 24/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 23/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9;, score=0.668 total time=   0.3s\n",
      "[CV 1/5; 25/972] START colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=120, subsample=0.8\n",
      "[CV 5/5; 23/972] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9;, score=0.646 total time=   0.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(model, param_grid, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Entraînez le modèle en utilisant la recherche par grille\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Affichez les meilleurs hyperparamètres trouvés\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMeilleurs hyperparamètres:\u001b[39m\u001b[39m\"\u001b[39m, grid_search\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow3/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1698\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1699\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1700\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Spécifiez la grille des hyperparamètres à explorer\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.05 ,0.06], # fraction de la correction appliquée\n",
    "    'n_estimators': [50, 100, 120], # nombre d arbres a entrainer séquentiellement pour faire prédicteur final (biais /variance)\n",
    "    'max_depth': [3, 4, 5], #profondeur maximale de ce que peut atteindre un arbre et donc des valeurs qu'il peut prendre soit 2^max_depth\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [ 0.1, 0.2], #définit le seuil du gain qu'apporte l'ajou de chaque nouveau noeud (0 -> pas de seuil)\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 0.7],\n",
    "}\n",
    "\n",
    "# Créez un objet GridSearchCV pour la recherche par grille\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=5, verbose=10, n_jobs=-1)\n",
    "\n",
    "# Entraînez le modèle en utilisant la recherche par grille\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Affichez les meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7066849126907246\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_ #enregistre les meilleurs paramètres trouvés.\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)  # Remplacez XGBClassifier par le modèle que vous utilisez\n",
    "\n",
    "best_model.fit(X_train, y_train) #entrainer le modèle avec les meilleurs paramètres trouvés.\n",
    "\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # prédire sur la partie X_test par vos données de test\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # Remplacez y_test par vos étiquettes de test\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette approche nous arrivons au score 0.70 ROC_AUC ce qui est suppérieur au score de 0.675 obtenu par Valéo en utilisant une   classification naïve bayésienne. \n",
    "\n",
    "Pour l'obtention de ce score, les meilleurs hyperparamètres sont :  {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.06, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
    "\n",
    "Néanmoins, l'inconvénient de l'approche est qu'il est très probable quelle soit biaisée par l'invention de l'humain. Le champs des paramètres possibles étant très large , le risque de tomber sur un 'minimal local' est donc très important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 2 : Recherche aléatoire (avec RandomizedSearchCV)\n",
    "\n",
    "Randomized Search sélectionne aléatoirement un nombre spécifié de combinaisons d'hyperparamètres à partir de l'espace d'hyperparamètres. Il effectue une recherche aléatoire parmi un sous-ensemble d'hyperparamètres, ce qui peut être plus efficace que Grid Search en termes de temps de calcul.\n",
    "\n",
    "L'approche est de définir un nombre fixe de combinaison a tester , RandomizedSearchCV selectionne aléatoirement les valeurs pour chaque hyperparamètre a chaque itération. Cette approche a plusieurs avantanges : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = { #définition de l espace de recherche  \n",
    "    'max_depth': range(3, 10),\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    'n_estimators': range(50, 200),\n",
    "    'subsample': [0.5, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.8, 1.0],\n",
    "    'min_child_weight': range(1, 10),\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5000,  # Nombre d'itérations d'optimisation\n",
    "    cv=5,  # Nombre pour la validation croisée\n",
    "    scoring='roc_auc',  # Métrique de performance (ROC AUC)\n",
    "    verbose=2,  # Afficher des détails pendant la recherche\n",
    "    n_jobs=-1,  # Utiliser tous les cœurs du CPU\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Exécuter la recherche d'hyperparamètres\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres: {'subsample': 1.0, 'n_estimators': 84, 'min_child_weight': 5, 'max_depth': 9, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
      "Best score = 0.658 after 5000 runs\n"
     ]
    }
   ],
   "source": [
    "# Afficher les meilleurs hyperparamètres trouvés\n",
    "best_params = random_search.best_params_\n",
    "print(\"Meilleurs hyperparamètres:\", best_params)\n",
    "print(\"Best score = %.3f after %d runs\" % (random_search.best_score_, random_search.n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score = 0.662 after 2000 runs\n",
    "\n",
    "Best score = 0.662 after 4000 runs\n",
    "\n",
    "Best score = 0.658 after 4000 runs\n",
    "\n",
    "Best score = 0.658 after 5000 runs 23min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 3: Processus bayesien (BayesSearchCV de Scikit-optimize)\n",
    "\n",
    "L’idée  de l’optimisation bayésienne est de minimiser le nombre d’observations tout en convergeant rapidement vers la solution optimale. Concrétement l'algorithme déterminerait la prochaine configuration ayant le plus de potentiel à tester en fonction des résultats des itérations précédentes en s'appuyant sur un processus gaussien.\n",
    "\n",
    "Pour cela, il convient de connaître trois principes fondamentaux:\n",
    "- Le processus Gaussien : d’exploiter les observations connues pour en déduire des probabilités d’événement qui n’ont pas encore été observées. Pour cela, il convient de déterminer pour chaque valeur X la distribution de probabilité. Le processus n'est pas applicable a toutes les observations a cause des limites de capacités calculatoires.\n",
    "\n",
    "- Déterminer les points à plus fort potentiel avec la fonction d’acquisition : gagner en connaissance sur le comportement de la fonction et donc choisir une zone de l’espace de recherche où l’inconnu est grand : c’est l’exploration. D’autre part, nous souhaitons trouver le point qui minimise/maximise notre fonction : c’est l’exploitation. Ce compromis entre exploration et exploitation est exprimé par une fonction d’acquisition\n",
    "\n",
    "- La fonction d’acquisition : Deux raisons permettent à une configuration donnée d’augmenter son potentiel, soit être dans une région loin de toutes configurations testées précédemment ou être dans une région près d’une configuration performante. En combinant ces deux critères, l’optimisation bayésienne cherche à réduire l’incertitude en explorant les régions peu explorées tout en exploitant les régions près d’une configuration performante. C’est ce qu’on appelle une fonction d’acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space\n",
    "search_spaces = {\n",
    "     'learning_rate': np.arange(0.01, 1.0),\n",
    "     'max_depth': np.arange(2, 20),\n",
    "     'reg_lambda': np.arange(1e-9, 100),\n",
    "     'reg_alpha': np.arange(1e-9, 100),\n",
    "     'gamma': np.arange(1e-9, 0.5),  \n",
    "     'n_estimators': np.arange(10, 5000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bayesian CV for HP optimization\n",
    "bayes_cv = BayesSearchCV(\n",
    "                    estimator = model,                                    \n",
    "                    search_spaces = search_spaces,                      \n",
    "                    scoring = 'roc_auc',                                  \n",
    "                    cv = 5,                                   \n",
    "                    n_iter = 20,                                      \n",
    "                    n_points = 5,                                       \n",
    "                    n_jobs = -1,                                        \n",
    "                    refit=False,\n",
    "                    verbose = 1,\n",
    "                    random_state=42\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "CPU times: user 46.1 s, sys: 9.92 s, total: 56 s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, device=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=True,\n",
       "                                      eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "                                      gamma=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=...\n",
       "       5.6e+01, 5.7e+01, 5.8e+01, 5.9e+01, 6.0e+01, 6.1e+01, 6.2e+01,\n",
       "       6.3e+01, 6.4e+01, 6.5e+01, 6.6e+01, 6.7e+01, 6.8e+01, 6.9e+01,\n",
       "       7.0e+01, 7.1e+01, 7.2e+01, 7.3e+01, 7.4e+01, 7.5e+01, 7.6e+01,\n",
       "       7.7e+01, 7.8e+01, 7.9e+01, 8.0e+01, 8.1e+01, 8.2e+01, 8.3e+01,\n",
       "       8.4e+01, 8.5e+01, 8.6e+01, 8.7e+01, 8.8e+01, 8.9e+01, 9.0e+01,\n",
       "       9.1e+01, 9.2e+01, 9.3e+01, 9.4e+01, 9.5e+01, 9.6e+01, 9.7e+01,\n",
       "       9.8e+01, 9.9e+01])},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, device=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=True,\n",
       "                                      eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "                                      gamma=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=...\n",
       "       5.6e+01, 5.7e+01, 5.8e+01, 5.9e+01, 6.0e+01, 6.1e+01, 6.2e+01,\n",
       "       6.3e+01, 6.4e+01, 6.5e+01, 6.6e+01, 6.7e+01, 6.8e+01, 6.9e+01,\n",
       "       7.0e+01, 7.1e+01, 7.2e+01, 7.3e+01, 7.4e+01, 7.5e+01, 7.6e+01,\n",
       "       7.7e+01, 7.8e+01, 7.9e+01, 8.0e+01, 8.1e+01, 8.2e+01, 8.3e+01,\n",
       "       8.4e+01, 8.5e+01, 8.6e+01, 8.7e+01, 8.8e+01, 8.9e+01, 9.0e+01,\n",
       "       9.1e+01, 9.2e+01, 9.3e+01, 9.4e+01, 9.5e+01, 9.6e+01, 9.7e+01,\n",
       "       9.8e+01, 9.9e+01])},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster='gbtree',\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, device=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=True,\n",
       "                                      eval_metric='auc', feature_types=None,\n",
       "                                      gamma=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=...\n",
       "       5.6e+01, 5.7e+01, 5.8e+01, 5.9e+01, 6.0e+01, 6.1e+01, 6.2e+01,\n",
       "       6.3e+01, 6.4e+01, 6.5e+01, 6.6e+01, 6.7e+01, 6.8e+01, 6.9e+01,\n",
       "       7.0e+01, 7.1e+01, 7.2e+01, 7.3e+01, 7.4e+01, 7.5e+01, 7.6e+01,\n",
       "       7.7e+01, 7.8e+01, 7.9e+01, 8.0e+01, 8.1e+01, 8.2e+01, 8.3e+01,\n",
       "       8.4e+01, 8.5e+01, 8.6e+01, 8.7e+01, 8.8e+01, 8.9e+01, 9.0e+01,\n",
       "       9.1e+01, 9.2e+01, 9.3e+01, 9.4e+01, 9.5e+01, 9.6e+01, 9.7e+01,\n",
       "       9.8e+01, 9.9e+01])},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run bayesian CV\n",
    "%time bayes_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "Best score = 0.626 after 30 runs\n"
     ]
    }
   ],
   "source": [
    "# Show best params\n",
    "print('Best parameters:')\n",
    "print(\"Best score = %.3f after %d runs\" % (bayes_cv.best_score_, bayes_cv.n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score = 0.630 after 20 runs\n",
    "\n",
    "Best score = 0.638 after 300 runs - 35min 27s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 4: Approche 'HalvingRandomSearchCV' & 'HalvingGridSearchCV' ( to document)\n",
    "Permet d'explorer le champs des possibles sans forcément trouver la combinaison optimale. L'avantage que présente cette méthode est de pouvoir maitriser le temps de calcul.\n",
    "Chercher des paramètres sur des échantillons de plus en plus important en écartant a chaque itération la moitiée des combinaisons les moins performantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import HalvingGridSearchCV \n",
    "from sklearn.model_selection import HalvingRandomSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dist = {\n",
    "    'learning_rate': [0.1, 0.05, 0.3, 0.2, 0.4 ,0.6, 0.7, 0.01],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "halving_grid = HalvingGridSearchCV(model,\n",
    "                           param_grid= param_dist, \n",
    "                           cv=5, \n",
    "                           scoring='roc_auc',\n",
    "                           n_jobs=-1, \n",
    "                           random_state=42,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 1022\n",
      "max_resources_: 27612\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 72\n",
      "n_resources: 1022\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 24\n",
      "n_resources: 3066\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 8\n",
      "n_resources: 9198\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 27594\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=True,\n",
       "                                            eval_metric=&#x27;auc&#x27;,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=None, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...),\n",
       "                    n_jobs=-1,\n",
       "                    param_grid={&#x27;learning_rate&#x27;: [0.1, 0.05, 0.3, 0.2, 0.4, 0.6,\n",
       "                                                  0.7, 0.01],\n",
       "                                &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                                &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                    random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=True,\n",
       "                                            eval_metric=&#x27;auc&#x27;,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=None, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...),\n",
       "                    n_jobs=-1,\n",
       "                    param_grid={&#x27;learning_rate&#x27;: [0.1, 0.05, 0.3, 0.2, 0.4, 0.6,\n",
       "                                                  0.7, 0.01],\n",
       "                                &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                                &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                    random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(estimator=XGBClassifier(base_score=None, booster='gbtree',\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=True,\n",
       "                                            eval_metric='auc',\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=None, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...),\n",
       "                    n_jobs=-1,\n",
       "                    param_grid={'learning_rate': [0.1, 0.05, 0.3, 0.2, 0.4, 0.6,\n",
       "                                                  0.7, 0.01],\n",
       "                                'max_depth': [3, 5, 7],\n",
       "                                'n_estimators': [100, 200, 300]},\n",
       "                    random_state=42, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécuter la recherche d'hyperparamètres\n",
    "halving_grid.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774562370316416\n"
     ]
    }
   ],
   "source": [
    "# Afficher les performances des meilleurs paramètres\n",
    "score = halving_grid.score(X, y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 5 : SMAC (Sequential Model-based Algorithm Configuration) - Forets aléatoires  (to do)\n",
    "\n",
    "SMAC est un framework d'optimisation basé sur des modèles séquentiels. Il est principalement utilisé pour automatiser la recherche des meilleurs hyperparamètres pour un algorithme d'apprentissage automatique donné. SMAC utilise des modèles statistiques pour modéliser la relation entre les hyperparamètres et la fonction de coût. Il recherche les hyperparamètres les plus prometteurs en utilisant une approche séquentielle, en essayant de minimiser la fonction de coût prédite par le modèle.\n",
    "SMAC équilibre l'exploitation (exploration des valeurs déjà connues prometteuses) et l'exploration (essai de nouvelles valeurs) pour rechercher efficacement l'espace des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 6: Hyperopt, Optuna, gpyopt (to do)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
